{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EnsembleNet_Top.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vmPdfhbX1u2",
        "outputId": "baf8ef97-9c69-4f29-9692-ff0389d440a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bIRv7nYm12C4",
        "outputId": "2af1f2d5-8e78-4cd1-95ae-e3d6099255bb"
      },
      "source": [
        "import os\n",
        "proj_path = '/content/drive/MyDrive/Model Development '\n",
        "os.chdir(proj_path)\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1_QHmZZAWiu1Idc_qP56o_8AWHyZMtSIR/Model Development '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiyXvnOa2BMl",
        "outputId": "0677e808-96c4-4f25-90c9-01d1485d34c0"
      },
      "source": [
        "#Imports\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Concatenate\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model\n",
        "!pip install -q pydot\n",
        "!pip install graphviz\n",
        "!pip install pydotplus\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pydotplus) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMHMUco2FHW"
      },
      "source": [
        "#image sizing\n",
        "IMAGE_SIZE=[224,224,3]\n",
        "train_path='/content/drive/MyDrive/Model Development /tbdataset/Train'\n",
        "valid_path='/content/drive/MyDrive/Model Development /tbdataset/Test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EINfLXIH2IE2",
        "outputId": "afcbb85f-57e2-4da8-fd6a-3fe68e7d7e88"
      },
      "source": [
        "# Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Preprocessing the Train set\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Model Development /tbdataset/Train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "# Preprocessing the Test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Model Development /tbdataset/Test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical',\n",
        "                                            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3167 images belonging to 2 classes.\n",
            "Found 791 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXcra33X4gD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f6582d-4d9b-4088-eb60-eb2fed0e9b51"
      },
      "source": [
        "IMAGE_SIZE = (224,224,3)\n",
        "\n",
        "vgg19 = tf.keras.applications.vgg19.VGG19(\n",
        "    input_shape=IMAGE_SIZE, weights='imagenet', include_top=False)\n",
        "for layer in vgg19.layers:\n",
        "    layer._name = layer._name + str('_19')\n",
        "    layer.trainable = False\n",
        "\n",
        "vgg16 = tf.keras.applications.vgg16.VGG16(\n",
        "    input_shape=IMAGE_SIZE, weights='imagenet', include_top=False)\n",
        "for layer in vgg16.layers:\n",
        "    layer._name = layer._name + str('_16')\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvVAiMGyJvZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06a63c0-3554-463d-8099-d1f369f532b2"
      },
      "source": [
        "inp = Input(IMAGE_SIZE)\n",
        "    \n",
        "vgg16_x = Flatten()(vgg16(inp))\n",
        "vgg19_x = Flatten()(vgg19(inp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv4/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block3_conv4/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv4/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block4_conv4/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_26), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_26), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_27), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_27), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_28), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv4/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_28), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'block5_conv4/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl28FqLyKZah",
        "outputId": "8041a53e-7f43-4940-b019-7d1142ed1f7e"
      },
      "source": [
        "x = Concatenate()([vgg16_x, vgg19_x])\n",
        "out = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs = inp, outputs = out)\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0005,\n",
        "    name=\"Adam\"),\n",
        "  metrics=['accuracy',\n",
        "           'AUC',\n",
        "           'Precision',\n",
        "           'Recall',\n",
        "  ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_13 (TFOpLambd (None, 224, 224, 64) 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_13 (TFOpLambda)  (None, 224, 224, 64) 0           tf.nn.convolution_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_13 (TFOpLambda)      (None, 224, 224, 64) 0           tf.nn.bias_add_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_14 (TFOpLambd (None, 224, 224, 64) 0           tf.nn.relu_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_14 (TFOpLambda)  (None, 224, 224, 64) 0           tf.nn.convolution_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_14 (TFOpLambda)      (None, 224, 224, 64) 0           tf.nn.bias_add_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_5 (TFO (None, 112, 112, 64) 0           tf.nn.relu_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_15 (TFOpLambd (None, 112, 112, 128 0           tf.compat.v1.nn.max_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_15 (TFOpLambda)  (None, 112, 112, 128 0           tf.nn.convolution_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution (TFOpLambda)  (None, 224, 224, 64) 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_15 (TFOpLambda)      (None, 112, 112, 128 0           tf.nn.bias_add_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add (TFOpLambda)     (None, 224, 224, 64) 0           tf.nn.convolution[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_16 (TFOpLambd (None, 112, 112, 128 0           tf.nn.relu_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)         (None, 224, 224, 64) 0           tf.nn.bias_add[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_16 (TFOpLambda)  (None, 112, 112, 128 0           tf.nn.convolution_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_1 (TFOpLambda (None, 224, 224, 64) 0           tf.nn.relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_16 (TFOpLambda)      (None, 112, 112, 128 0           tf.nn.bias_add_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_1 (TFOpLambda)   (None, 224, 224, 64) 0           tf.nn.convolution_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_6 (TFO (None, 56, 56, 128)  0           tf.nn.relu_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)       (None, 224, 224, 64) 0           tf.nn.bias_add_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_17 (TFOpLambd (None, 56, 56, 256)  0           tf.compat.v1.nn.max_pool_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool (TFOpL (None, 112, 112, 64) 0           tf.nn.relu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_17 (TFOpLambda)  (None, 56, 56, 256)  0           tf.nn.convolution_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_2 (TFOpLambda (None, 112, 112, 128 0           tf.compat.v1.nn.max_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_17 (TFOpLambda)      (None, 56, 56, 256)  0           tf.nn.bias_add_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_2 (TFOpLambda)   (None, 112, 112, 128 0           tf.nn.convolution_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_18 (TFOpLambd (None, 56, 56, 256)  0           tf.nn.relu_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)       (None, 112, 112, 128 0           tf.nn.bias_add_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_18 (TFOpLambda)  (None, 56, 56, 256)  0           tf.nn.convolution_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_3 (TFOpLambda (None, 112, 112, 128 0           tf.nn.relu_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_18 (TFOpLambda)      (None, 56, 56, 256)  0           tf.nn.bias_add_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_3 (TFOpLambda)   (None, 112, 112, 128 0           tf.nn.convolution_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_19 (TFOpLambd (None, 56, 56, 256)  0           tf.nn.relu_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)       (None, 112, 112, 128 0           tf.nn.bias_add_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_19 (TFOpLambda)  (None, 56, 56, 256)  0           tf.nn.convolution_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_1 (TFO (None, 56, 56, 128)  0           tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_19 (TFOpLambda)      (None, 56, 56, 256)  0           tf.nn.bias_add_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_4 (TFOpLambda (None, 56, 56, 256)  0           tf.compat.v1.nn.max_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_20 (TFOpLambd (None, 56, 56, 256)  0           tf.nn.relu_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_4 (TFOpLambda)   (None, 56, 56, 256)  0           tf.nn.convolution_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_20 (TFOpLambda)  (None, 56, 56, 256)  0           tf.nn.convolution_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)       (None, 56, 56, 256)  0           tf.nn.bias_add_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_20 (TFOpLambda)      (None, 56, 56, 256)  0           tf.nn.bias_add_20[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_5 (TFOpLambda (None, 56, 56, 256)  0           tf.nn.relu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_7 (TFO (None, 28, 28, 256)  0           tf.nn.relu_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_5 (TFOpLambda)   (None, 56, 56, 256)  0           tf.nn.convolution_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_21 (TFOpLambd (None, 28, 28, 512)  0           tf.compat.v1.nn.max_pool_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)       (None, 56, 56, 256)  0           tf.nn.bias_add_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_21 (TFOpLambda)  (None, 28, 28, 512)  0           tf.nn.convolution_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_6 (TFOpLambda (None, 56, 56, 256)  0           tf.nn.relu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_21 (TFOpLambda)      (None, 28, 28, 512)  0           tf.nn.bias_add_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_6 (TFOpLambda)   (None, 56, 56, 256)  0           tf.nn.convolution_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_22 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)       (None, 56, 56, 256)  0           tf.nn.bias_add_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_22 (TFOpLambda)  (None, 28, 28, 512)  0           tf.nn.convolution_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_2 (TFO (None, 28, 28, 256)  0           tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_22 (TFOpLambda)      (None, 28, 28, 512)  0           tf.nn.bias_add_22[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_7 (TFOpLambda (None, 28, 28, 512)  0           tf.compat.v1.nn.max_pool_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_23 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_7 (TFOpLambda)   (None, 28, 28, 512)  0           tf.nn.convolution_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_23 (TFOpLambda)  (None, 28, 28, 512)  0           tf.nn.convolution_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)       (None, 28, 28, 512)  0           tf.nn.bias_add_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_23 (TFOpLambda)      (None, 28, 28, 512)  0           tf.nn.bias_add_23[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_8 (TFOpLambda (None, 28, 28, 512)  0           tf.nn.relu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_24 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_8 (TFOpLambda)   (None, 28, 28, 512)  0           tf.nn.convolution_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_24 (TFOpLambda)  (None, 28, 28, 512)  0           tf.nn.convolution_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_8 (TFOpLambda)       (None, 28, 28, 512)  0           tf.nn.bias_add_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_24 (TFOpLambda)      (None, 28, 28, 512)  0           tf.nn.bias_add_24[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_9 (TFOpLambda (None, 28, 28, 512)  0           tf.nn.relu_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_8 (TFO (None, 14, 14, 512)  0           tf.nn.relu_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_9 (TFOpLambda)   (None, 28, 28, 512)  0           tf.nn.convolution_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_25 (TFOpLambd (None, 14, 14, 512)  0           tf.compat.v1.nn.max_pool_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_9 (TFOpLambda)       (None, 28, 28, 512)  0           tf.nn.bias_add_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_25 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_3 (TFO (None, 14, 14, 512)  0           tf.nn.relu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_25 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_25[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_10 (TFOpLambd (None, 14, 14, 512)  0           tf.compat.v1.nn.max_pool_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_26 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_10 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_26 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_10 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_26 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_26[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_11 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_27 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_11 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_27 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_11 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_27 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_27[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_12 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_28 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_12 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_28 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_12 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_28 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_28[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_4 (TFO (None, 7, 7, 512)    0           tf.nn.relu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_9 (TFO (None, 7, 7, 512)    0           tf.nn.relu_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 25088)        0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 25088)        0           tf.compat.v1.nn.max_pool_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 50176)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 2)            100354      concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 100,354\n",
            "Trainable params: 100,354\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7bJs3kxLaeF",
        "outputId": "15551d95-9dd4-47f4-b263-d05bd7e1b044"
      },
      "source": [
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=20,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "99/99 [==============================] - 2590s 26s/step - loss: 0.5691 - accuracy: 0.7390 - auc: 0.8041 - precision: 0.7390 - recall: 0.7390 - val_loss: 0.2393 - val_accuracy: 0.9140 - val_auc: 0.9651 - val_precision: 0.9140 - val_recall: 0.9140\n",
            "Epoch 2/20\n",
            "99/99 [==============================] - 217s 2s/step - loss: 0.2707 - accuracy: 0.8974 - auc: 0.9545 - precision: 0.8974 - recall: 0.8974 - val_loss: 0.2089 - val_accuracy: 0.9267 - val_auc: 0.9728 - val_precision: 0.9267 - val_recall: 0.9267\n",
            "Epoch 3/20\n",
            "99/99 [==============================] - 206s 2s/step - loss: 0.2311 - accuracy: 0.9081 - auc: 0.9675 - precision: 0.9081 - recall: 0.9081 - val_loss: 0.2062 - val_accuracy: 0.9178 - val_auc: 0.9742 - val_precision: 0.9178 - val_recall: 0.9178\n",
            "Epoch 4/20\n",
            "99/99 [==============================] - 213s 2s/step - loss: 0.2148 - accuracy: 0.9041 - auc: 0.9718 - precision: 0.9041 - recall: 0.9041 - val_loss: 0.3614 - val_accuracy: 0.8559 - val_auc: 0.9370 - val_precision: 0.8559 - val_recall: 0.8559\n",
            "Epoch 5/20\n",
            "99/99 [==============================] - 213s 2s/step - loss: 0.2474 - accuracy: 0.9024 - auc: 0.9637 - precision: 0.9024 - recall: 0.9024 - val_loss: 0.2114 - val_accuracy: 0.9191 - val_auc: 0.9729 - val_precision: 0.9191 - val_recall: 0.9191\n",
            "Epoch 6/20\n",
            "99/99 [==============================] - 217s 2s/step - loss: 0.2098 - accuracy: 0.9198 - auc: 0.9730 - precision: 0.9198 - recall: 0.9198 - val_loss: 0.2149 - val_accuracy: 0.9191 - val_auc: 0.9713 - val_precision: 0.9191 - val_recall: 0.9191\n",
            "Epoch 7/20\n",
            "99/99 [==============================] - 217s 2s/step - loss: 0.1679 - accuracy: 0.9325 - auc: 0.9824 - precision: 0.9325 - recall: 0.9325 - val_loss: 0.2022 - val_accuracy: 0.9204 - val_auc: 0.9756 - val_precision: 0.9204 - val_recall: 0.9204\n",
            "Epoch 8/20\n",
            "99/99 [==============================] - 216s 2s/step - loss: 0.1987 - accuracy: 0.9151 - auc: 0.9763 - precision: 0.9151 - recall: 0.9151 - val_loss: 0.4585 - val_accuracy: 0.8432 - val_auc: 0.9231 - val_precision: 0.8432 - val_recall: 0.8432\n",
            "Epoch 9/20\n",
            "99/99 [==============================] - 217s 2s/step - loss: 0.1977 - accuracy: 0.9212 - auc: 0.9763 - precision: 0.9212 - recall: 0.9212 - val_loss: 0.1800 - val_accuracy: 0.9368 - val_auc: 0.9805 - val_precision: 0.9368 - val_recall: 0.9368\n",
            "Epoch 10/20\n",
            "99/99 [==============================] - 218s 2s/step - loss: 0.1332 - accuracy: 0.9532 - auc: 0.9892 - precision: 0.9532 - recall: 0.9532 - val_loss: 0.1860 - val_accuracy: 0.9216 - val_auc: 0.9795 - val_precision: 0.9216 - val_recall: 0.9216\n",
            "Epoch 11/20\n",
            "99/99 [==============================] - 217s 2s/step - loss: 0.1574 - accuracy: 0.9432 - auc: 0.9845 - precision: 0.9432 - recall: 0.9432 - val_loss: 0.1818 - val_accuracy: 0.9241 - val_auc: 0.9799 - val_precision: 0.9241 - val_recall: 0.9241\n",
            "Epoch 12/20\n",
            "99/99 [==============================] - 215s 2s/step - loss: 0.1529 - accuracy: 0.9344 - auc: 0.9858 - precision: 0.9344 - recall: 0.9344 - val_loss: 0.2435 - val_accuracy: 0.9140 - val_auc: 0.9663 - val_precision: 0.9140 - val_recall: 0.9140\n",
            "Epoch 13/20\n",
            "99/99 [==============================] - 221s 2s/step - loss: 0.1313 - accuracy: 0.9534 - auc: 0.9894 - precision: 0.9534 - recall: 0.9534 - val_loss: 0.1662 - val_accuracy: 0.9381 - val_auc: 0.9832 - val_precision: 0.9381 - val_recall: 0.9381\n",
            "Epoch 14/20\n",
            "99/99 [==============================] - 218s 2s/step - loss: 0.1346 - accuracy: 0.9472 - auc: 0.9887 - precision: 0.9472 - recall: 0.9472 - val_loss: 0.1616 - val_accuracy: 0.9444 - val_auc: 0.9845 - val_precision: 0.9444 - val_recall: 0.9444\n",
            "Epoch 15/20\n",
            "99/99 [==============================] - 222s 2s/step - loss: 0.1273 - accuracy: 0.9496 - auc: 0.9900 - precision: 0.9496 - recall: 0.9496 - val_loss: 0.2391 - val_accuracy: 0.9102 - val_auc: 0.9687 - val_precision: 0.9102 - val_recall: 0.9102\n",
            "Epoch 16/20\n",
            "99/99 [==============================] - 217s 2s/step - loss: 0.1359 - accuracy: 0.9486 - auc: 0.9882 - precision: 0.9486 - recall: 0.9486 - val_loss: 0.2727 - val_accuracy: 0.9077 - val_auc: 0.9619 - val_precision: 0.9077 - val_recall: 0.9077\n",
            "Epoch 17/20\n",
            "99/99 [==============================] - 221s 2s/step - loss: 0.1287 - accuracy: 0.9466 - auc: 0.9896 - precision: 0.9466 - recall: 0.9466 - val_loss: 0.1705 - val_accuracy: 0.9368 - val_auc: 0.9816 - val_precision: 0.9368 - val_recall: 0.9368\n",
            "Epoch 18/20\n",
            "99/99 [==============================] - 221s 2s/step - loss: 0.1133 - accuracy: 0.9522 - auc: 0.9916 - precision: 0.9522 - recall: 0.9522 - val_loss: 0.7282 - val_accuracy: 0.7876 - val_auc: 0.8801 - val_precision: 0.7876 - val_recall: 0.7876\n",
            "Epoch 19/20\n",
            "99/99 [==============================] - 219s 2s/step - loss: 0.1669 - accuracy: 0.9322 - auc: 0.9829 - precision: 0.9322 - recall: 0.9322 - val_loss: 0.1618 - val_accuracy: 0.9355 - val_auc: 0.9838 - val_precision: 0.9355 - val_recall: 0.9355\n",
            "Epoch 20/20\n",
            "99/99 [==============================] - 220s 2s/step - loss: 0.0984 - accuracy: 0.9592 - auc: 0.9942 - precision: 0.9592 - recall: 0.9592 - val_loss: 0.2004 - val_accuracy: 0.9305 - val_auc: 0.9755 - val_precision: 0.9305 - val_recall: 0.9305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGTGYhVMNlPz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "9221350a-93e2-4e5e-dc5e-4efd232ca954"
      },
      "source": [
        "model.save('saved_models/ensemblevgg') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-18a4ec935d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models/ensemblevgg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2085\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2087\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m   def save_weights(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 151\u001b[0;31m                             signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0;32m---> 91\u001b[0;31m           model, filepath, signatures, options)\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Save all metadata to a separate file in the SavedModel directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, raise_metadata_warning, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[1;32m   1103\u001b[0m       _build_meta_graph(obj, signatures, options, meta_graph_def,\n\u001b[0;32m-> 1104\u001b[0;31m                         raise_metadata_warning))\n\u001b[0m\u001b[1;32m   1105\u001b[0m   \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_schema_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_SCHEMA_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def, raise_metadata_warning)\u001b[0m\n\u001b[1;32m   1289\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m     return _build_meta_graph_impl(obj, signatures, options, meta_graph_def,\n\u001b[0;32m-> 1291\u001b[0;31m                                   raise_metadata_warning)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def, raise_metadata_warning)\u001b[0m\n\u001b[1;32m   1223\u001b[0m   asset_info, exported_graph = _fill_meta_graph_def(meta_graph_def,\n\u001b[1;32m   1224\u001b[0m                                                     \u001b[0msaveable_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m                                                     options.namespace_whitelist)\n\u001b[0m\u001b[1;32m   1226\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_aliases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0mfunction_aliases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_info_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_aliases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_fill_meta_graph_def\u001b[0;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mexported_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     \u001b[0msignatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_generate_signatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconcrete_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcrete_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_generate_signatures\u001b[0;34m(signature_functions, resource_map)\u001b[0m\n\u001b[1;32m    580\u001b[0m                                                   signature_key, function.name))\n\u001b[1;32m    581\u001b[0m     outputs = _call_function_with_mapped_captures(\n\u001b[0;32m--> 582\u001b[0;31m         function, mapped_inputs, resource_map)\n\u001b[0m\u001b[1;32m    583\u001b[0m     signatures[signature_key] = signature_def_utils.build_signature_def(\n\u001b[1;32m    584\u001b[0m         \u001b[0m_tensor_dict_to_tensorinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexterior_argument_placeholders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_call_function_with_mapped_captures\u001b[0;34m(function, args, resource_map)\u001b[0m\n\u001b[1;32m    532\u001b[0m   \u001b[0;34m\"\"\"Calls `function` in the exported graph, using mapped resource captures.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m   export_captures = _map_captures_to_created_tensors(function.graph.captures,\n\u001b[0;32m--> 534\u001b[0;31m                                                      resource_map)\n\u001b[0m\u001b[1;32m    535\u001b[0m   \u001b[0;31m# Calls the function quite directly, since we have new captured resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m   \u001b[0;31m# tensors we need to feed in which weren't part of the original function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_map_captures_to_created_tensors\u001b[0;34m(original_captures, resource_map)\u001b[0m\n\u001b[1;32m    455\u001b[0m            \u001b[0;34m\"(from gc.get_referrers, limited to two hops):\\n{}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m           \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                    \"\\n\".join([repr(obj) for obj in trackable_referrers])))\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0mexport_captures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexport_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Tried to export a function which references untracked resource Tensor(\"18908:0\", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\n\nTrackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):\n<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkDZ5efXeWgH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sy9NSIGaqnf",
        "outputId": "b1bf6fb7-f027-4c23-d0a3-d9bad35b3524"
      },
      "source": [
        "predictions = model.predict(test_set, steps = test_set.n // 31, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 26s 1s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24KWj9HfbLB6"
      },
      "source": [
        "y_classes = predictions.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkmjsla1bn6T"
      },
      "source": [
        "test_set.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXRzdqvBbjEe",
        "outputId": "e652c022-5cbf-4ba9-e0fd-65a6ea940a28"
      },
      "source": [
        "y_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lwSK_psbQKf",
        "outputId": "749029b9-ae30-426c-b544-fa09a2f4a2a2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(test_set.classes, y_classes))\n",
        "\n",
        "print(\"Accuracy : \" ,accuracy_score(test_set.classes, y_classes))\n",
        "print(\"Precision : \" ,precision_score(test_set.classes, y_classes))\n",
        "print(\"Recall : \" ,recall_score(test_set.classes, y_classes))\n",
        "print(\"F1 Score : \" ,f1_score(test_set.classes, y_classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[389   8]\n",
            " [ 47 347]]\n",
            "Accuracy :  0.9304677623261695\n",
            "Precision :  0.9774647887323944\n",
            "Recall :  0.8807106598984772\n",
            "F1 Score :  0.9265687583444593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XByQFJ4WbUiN",
        "outputId": "82001cb6-5460-4278-bffc-2578acbbd817"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, threshold = roc_curve(test_set.classes, y_classes)\n",
        "print(\"SVM Area under curve -> \",auc(fpr, tpr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Area under curve ->  0.9302797631986089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqI-z1oLbgfO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}