{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_ver7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeL8pin7w299",
        "outputId": "44eddf43-6805-40a9-b466-d3f8477cdd7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H2Jc0uD71UDw",
        "outputId": "466975a3-bcff-4253-d9a3-835f4757f549"
      },
      "source": [
        "import os\n",
        "proj_path = '/content/drive/MyDrive/CNN'\n",
        "os.chdir(proj_path)\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/CNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMPD71HH1U-A"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "data_path = '/content/drive/MyDrive/CNN/CNN_Datasets.zip' \n",
        "#with ZipFile(data_path, 'r') as f:\n",
        " # f.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8cWdTGA1O5x"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMLepbZ3JDY"
      },
      "source": [
        "#image sizing\n",
        "IMAGE_SIZE=[224,224,3]\n",
        "train_path='/content/drive/MyDrive/CNN/Datasets/train'\n",
        "valid_path='/content/drive/MyDrive/CNN/Datasets/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiLdNAUw29-"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbKaqytVw29_"
      },
      "source": [
        "# Part 1 - Data Preprocessing\n",
        "# Preprocessing the Training set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOVEHoNsw29_"
      },
      "source": [
        "def dataset(var):\n",
        "  training_set = train_datagen.flow_from_directory('Datasets/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = var,\n",
        "                                                 class_mode = 'categorical')\n",
        "  # Preprocessing the Test set\n",
        "  test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "  test_set = test_datagen.flow_from_directory('Datasets/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = var,\n",
        "                                            class_mode = 'categorical')\n",
        "  return(training_set,test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4KcVIc2xJMH"
      },
      "source": [
        "# Part 3 - Training the CNN\n",
        "def comp(var,training_set,test_set):\n",
        "  # Compiling the CNN\n",
        "  cnn.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=var,beta_1=0.9,beta_2=0.999,epsilon=1e-08,amsgrad=False,name=\"Adam\"), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  # Training the CNN on the Training set and evaluating it on the Test set\n",
        "  r=cnn.fit(x = training_set, validation_data = test_set, epochs = 10)\n",
        "  T_loss = r.history['loss']\n",
        "  V_loss = r.history['val_loss']\n",
        "  T_acc = r.history['accuracy']\n",
        "  V_acc = r.history['val_accuracy']\n",
        "  return(T_loss,V_loss,T_acc,V_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xiQPsCT1w2-A",
        "outputId": "303ebd2e-79f0-45fe-8a36-4a11b022f8aa"
      },
      "source": [
        "# defining variables\n",
        "x=[[],[],[],[],[],[],[],[],[],[],[],[]]\n",
        "print(x[7])\n",
        "lr=[0.01,0.001]\n",
        "bs = [32,64]\n",
        "t=0\n",
        "# Part 2 - Building the CNN\n",
        "for val in range(3):\n",
        "  if val == 0:\n",
        "    for i in range(2):\n",
        "      for j in range(2):\n",
        "        training_set,test_set= dataset(bs[i])\n",
        "        # Initialising the CNN\n",
        "        cnn = tf.keras.models.Sequential()\n",
        "        # Step 1 - Convolution\n",
        "        cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', input_shape=[224, 224, 3]))\n",
        "        # Step 2-1 - Pooling\n",
        "        cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        # Step 2-2 - conv + Pooling\n",
        "        cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', input_shape=[112, 112, 3]))\n",
        "        cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        # Step 2-3 - conv + Pooling\n",
        "        cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "        cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "        # Adding a dropout layer before visual layer\n",
        "        cnn.add(tf.keras.layers.Dropout(0.2, input_shape=(60,)))\n",
        "        # Step 3 - Flattening\n",
        "        cnn.add(tf.keras.layers.Flatten())\n",
        "        # Step 4 - Full Connection\n",
        "        cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "        # Step 5 - Output Layer\n",
        "        cnn.add(tf.keras.layers.Dense(units=3, activation='softmax'))\n",
        "        cnn.summary()\n",
        "        T_loss,V_loss,T_acc,V_acc= comp(lr[j],training_set,test_set)\n",
        "        x[t]=[T_loss,V_loss,T_acc,V_acc]\n",
        "        t = t+1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "Found 5144 images belonging to 3 classes.\n",
            "Found 1288 images belonging to 3 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 3,231,171\n",
            "Trainable params: 3,231,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 1814s 11s/step - loss: 1.9569 - accuracy: 0.6678 - val_loss: 0.8060 - val_accuracy: 0.6731\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 501s 3s/step - loss: 0.8060 - accuracy: 0.6621 - val_loss: 0.8185 - val_accuracy: 0.6638\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 492s 3s/step - loss: 0.7155 - accuracy: 0.6759 - val_loss: 0.6160 - val_accuracy: 0.7422\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 498s 3s/step - loss: 0.6097 - accuracy: 0.7411 - val_loss: 0.5913 - val_accuracy: 0.7508\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 502s 3s/step - loss: 0.5711 - accuracy: 0.7601 - val_loss: 0.3833 - val_accuracy: 0.8447\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 501s 3s/step - loss: 0.4342 - accuracy: 0.8250 - val_loss: 0.2749 - val_accuracy: 0.9092\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 498s 3s/step - loss: 0.3520 - accuracy: 0.8637 - val_loss: 0.2298 - val_accuracy: 0.9123\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 495s 3s/step - loss: 0.3247 - accuracy: 0.8713 - val_loss: 0.2248 - val_accuracy: 0.9161\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 501s 3s/step - loss: 0.3405 - accuracy: 0.8668 - val_loss: 0.2582 - val_accuracy: 0.9006\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 501s 3s/step - loss: 0.3034 - accuracy: 0.8812 - val_loss: 0.2443 - val_accuracy: 0.9076\n",
            "Found 5144 images belonging to 3 classes.\n",
            "Found 1288 images belonging to 3 classes.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 3,231,171\n",
            "Trainable params: 3,231,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 521s 3s/step - loss: 0.4840 - accuracy: 0.8208 - val_loss: 0.2259 - val_accuracy: 0.9208\n",
            "Epoch 2/10\n",
            "161/161 [==============================] - 516s 3s/step - loss: 0.2900 - accuracy: 0.8898 - val_loss: 0.2136 - val_accuracy: 0.9286\n",
            "Epoch 3/10\n",
            "161/161 [==============================] - 517s 3s/step - loss: 0.2751 - accuracy: 0.8935 - val_loss: 0.2065 - val_accuracy: 0.9185\n",
            "Epoch 4/10\n",
            "161/161 [==============================] - 526s 3s/step - loss: 0.2330 - accuracy: 0.9145 - val_loss: 0.1947 - val_accuracy: 0.9301\n",
            "Epoch 5/10\n",
            "161/161 [==============================] - 522s 3s/step - loss: 0.2281 - accuracy: 0.9150 - val_loss: 0.2867 - val_accuracy: 0.8998\n",
            "Epoch 6/10\n",
            "161/161 [==============================] - 516s 3s/step - loss: 0.2085 - accuracy: 0.9213 - val_loss: 0.1518 - val_accuracy: 0.9387\n",
            "Epoch 7/10\n",
            "161/161 [==============================] - 520s 3s/step - loss: 0.2051 - accuracy: 0.9250 - val_loss: 0.2627 - val_accuracy: 0.9123\n",
            "Epoch 8/10\n",
            "161/161 [==============================] - 519s 3s/step - loss: 0.2061 - accuracy: 0.9269 - val_loss: 0.1830 - val_accuracy: 0.9371\n",
            "Epoch 9/10\n",
            "161/161 [==============================] - 516s 3s/step - loss: 0.1857 - accuracy: 0.9271 - val_loss: 0.1837 - val_accuracy: 0.9317\n",
            "Epoch 10/10\n",
            "161/161 [==============================] - 515s 3s/step - loss: 0.1744 - accuracy: 0.9368 - val_loss: 0.2009 - val_accuracy: 0.9247\n",
            "Found 5144 images belonging to 3 classes.\n",
            "Found 1288 images belonging to 3 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 56, 56, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 3,231,171\n",
            "Trainable params: 3,231,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 499s 6s/step - loss: 2.1378 - accuracy: 0.6963 - val_loss: 0.3943 - val_accuracy: 0.8346\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 495s 6s/step - loss: 0.5707 - accuracy: 0.7784 - val_loss: 0.2848 - val_accuracy: 0.8983\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 498s 6s/step - loss: 0.3867 - accuracy: 0.8581 - val_loss: 0.2781 - val_accuracy: 0.9084\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 495s 6s/step - loss: 0.3341 - accuracy: 0.8756 - val_loss: 0.3195 - val_accuracy: 0.8998\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 497s 6s/step - loss: 0.3241 - accuracy: 0.8810 - val_loss: 0.3372 - val_accuracy: 0.9022\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 499s 6s/step - loss: 0.3063 - accuracy: 0.8847 - val_loss: 0.2906 - val_accuracy: 0.9138\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 497s 6s/step - loss: 0.3063 - accuracy: 0.8886 - val_loss: 0.2647 - val_accuracy: 0.9231\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 502s 6s/step - loss: 0.2816 - accuracy: 0.8993 - val_loss: 0.2718 - val_accuracy: 0.9146\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 493s 6s/step - loss: 0.2530 - accuracy: 0.9106 - val_loss: 0.2690 - val_accuracy: 0.9262\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 499s 6s/step - loss: 0.2579 - accuracy: 0.9067 - val_loss: 0.3274 - val_accuracy: 0.8975\n",
            "Found 5144 images belonging to 3 classes.\n",
            "Found 1288 images belonging to 3 classes.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 56, 56, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 3,231,171\n",
            "Trainable params: 3,231,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 519s 6s/step - loss: 0.5088 - accuracy: 0.7935 - val_loss: 0.2575 - val_accuracy: 0.9014\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 518s 6s/step - loss: 0.3175 - accuracy: 0.8775 - val_loss: 0.2285 - val_accuracy: 0.9177\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 515s 6s/step - loss: 0.2626 - accuracy: 0.9010 - val_loss: 0.2102 - val_accuracy: 0.9278\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 515s 6s/step - loss: 0.2406 - accuracy: 0.9082 - val_loss: 0.2151 - val_accuracy: 0.9278\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 513s 6s/step - loss: 0.2387 - accuracy: 0.9053 - val_loss: 0.1999 - val_accuracy: 0.9270\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 515s 6s/step - loss: 0.2201 - accuracy: 0.9182 - val_loss: 0.1971 - val_accuracy: 0.9363\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 507s 6s/step - loss: 0.2048 - accuracy: 0.9230 - val_loss: 0.1882 - val_accuracy: 0.9340\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 513s 6s/step - loss: 0.1912 - accuracy: 0.9257 - val_loss: 0.1694 - val_accuracy: 0.9495\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 510s 6s/step - loss: 0.1941 - accuracy: 0.9265 - val_loss: 0.2043 - val_accuracy: 0.9317\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 512s 6s/step - loss: 0.1978 - accuracy: 0.9269 - val_loss: 0.2192 - val_accuracy: 0.9138\n",
            "Found 5144 images belonging to 3 classes.\n",
            "Found 1288 images belonging to 3 classes.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 56, 56, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 3,231,171\n",
            "Trainable params: 3,231,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "161/161 [==============================] - 505s 3s/step - loss: 1.2661 - accuracy: 0.7298 - val_loss: 0.3558 - val_accuracy: 0.8602\n",
            "Epoch 2/10\n",
            "109/161 [===================>..........] - ETA: 2:25 - loss: 0.4003 - accuracy: 0.8437"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-382786f3ddf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mT_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV_acc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-76125d8c07f4>\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(var, training_set, test_set)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Training the CNN on the Training set and evaluating it on the Test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mT_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mV_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWBhx-qA_w_g",
        "outputId": "ab075432-6f7c-4872-c9e8-158a5bcf1741"
      },
      "source": [
        "x[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.956942081451416,\n",
              "  0.8060275912284851,\n",
              "  0.7154689431190491,\n",
              "  0.6097372770309448,\n",
              "  0.571069061756134,\n",
              "  0.43422043323516846,\n",
              "  0.351966917514801,\n",
              "  0.32466939091682434,\n",
              "  0.3404786288738251,\n",
              "  0.30337899923324585],\n",
              " [0.8060418367385864,\n",
              "  0.8185096979141235,\n",
              "  0.6160398721694946,\n",
              "  0.591273844242096,\n",
              "  0.38330772519111633,\n",
              "  0.27494171261787415,\n",
              "  0.22975151240825653,\n",
              "  0.22480472922325134,\n",
              "  0.25816023349761963,\n",
              "  0.2442762702703476],\n",
              " [0.6677682995796204,\n",
              "  0.6621306538581848,\n",
              "  0.6759331226348877,\n",
              "  0.7410575151443481,\n",
              "  0.7601088881492615,\n",
              "  0.8250389099121094,\n",
              "  0.8637247085571289,\n",
              "  0.8713063597679138,\n",
              "  0.8668351769447327,\n",
              "  0.881220817565918],\n",
              " [0.6731366515159607,\n",
              "  0.6638198494911194,\n",
              "  0.7422360181808472,\n",
              "  0.7507764101028442,\n",
              "  0.8447204828262329,\n",
              "  0.9091615080833435,\n",
              "  0.9122670888900757,\n",
              "  0.9161490797996521,\n",
              "  0.9006211161613464,\n",
              "  0.907608687877655]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d836xC3cc4TK"
      },
      "source": [
        "#save data\n",
        "np.savetxt(fname=\"DOVl_lr01_bs32.csv\", delimiter=\",\", X=x[0])\n",
        "np.savetxt(fname=\"DOVl_lr01_bs64.csv\", delimiter=\",\", X=x[1])\n",
        "np.savetxt(fname=\"DOVl_lr001_bs32.csv\", delimiter=\",\", X=x[2])\n",
        "np.savetxt(fname=\"DOVl_lr001_bs64.csv\", delimiter=\",\", X=x[3])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}